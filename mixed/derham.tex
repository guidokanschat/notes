\begin{intro}
  We can embed finite element methods for the Darcy problem, also for
  the Maxwell problem, into a common framework based on the de Rham
  complex. If we wanted to do this in its full mathematical beauty, we
  would have to spend some time introducing the concept and notation
  of differential forms. As an alternative, we can use the concrete
  vector spaces $\Hdiv(\domain)$ and $\Hcurl(\domain)$. The drawback
  is, that we have to prove several particular cases, where the
  abstract theory only knows one common case. Nevertheless, it is
  worthwhile to begin this way, such that the reader has an easier
  task reading the full theory
  in~\cite{ArnoldFalkWinther06acta,ArnoldFalkWinther10}. As a byproduct,
  we will prove in generality some of the properties of polynomial
  spaces in Chapter~\ref{cha:darcy}.
\end{intro}

\begin{intro}
  We now know three differential operators, $\nabla$, $\curl$, and
  $\div$ with the interesting property
  \begin{gather}
    \label{eq:derham:10}
    \curl\nabla \phi = 0
    \qquad \div\curl E=0.
  \end{gather}
  As a consequence, for $\phi\in H^1(\domain)$ we not only have
  $\nabla \phi\in L^2(\domain;\R^3)$, we also have
  $\curl\nabla\phi=0\in L^2(\domain;\R^3)$. This gives rise to the sequence
  \begin{gather}
    \label{eq:derham:11}
    \R
    \overset{\subset}{\longrightarrow} H^1(\domain)
    \overset{\nabla}{\longrightarrow} \Hcurl(\domain)
    \overset{\curl}{\longrightarrow} \Hdiv(\domain)
    \overset{\div}{\longrightarrow} L^2(\domain)
    \longrightarrow 0,
  \end{gather}
  such that the range of an operator is always in the kernel of the
  operator to its right.
\end{intro}

\begin{Notation}{hlambda}
  The notation of exterior calculus of differential forms allows us to
  write this sequence elegantly as
  \begin{gather}\minCDarrowwidth20pt
    \label{eq:derham:9}
    \begin{CD}
      \R
      @>{d}>> H\Lambda^0(\domain)
      @>{d}>> H\Lambda^1(\domain)
      @>{d}>> H\Lambda^2(\domain)
      @>{d}>> H\Lambda^3(\domain)
      @>>> 0
      \\
      @.
      @V{\cong}VV
      @V{\cong}VV
      @V{\cong}VV
      @V{\cong}VV
      \\
      \R
      @>{\subset}>> H^1(\domain)
      @>{\nabla}>> \Hcurl(\domain)
      @>{\curl}>> \Hdiv(\domain)
      @>{\div}>> L^2(\domain)
      @>>> 0,
    \end{CD}
  \end{gather}
  such that $d=d_k\colon H\Lambda^k(\domain) \to H\Lambda^{k+1}(\domain)$ and
  \begin{gather}
    d^2 = d\circ d = d_{k+1} \circ d_k = 0.
  \end{gather}
\end{Notation}

\begin{remark}
  The spaces $H\Lambda^k(\domain)$ are Hilbert spaces with values in
  the spaces of alternating $k$-forms on $\R^d$. From linear algebra,
  we know that all alternating $k$-forms are zero if $k$ exceeds the
  dimension of the vector space.  Therefore, the sequence above is
  only valid in three dimensions, and it must be shorter by one member
  in two dimensions. Changing our view back to differential operators,
  we realize that there are two relevant sequences in two
  dimensions. In the following diagram, the sequence on top can be
  used to formulate Maxwell problems in $\Hcurl$ in two dimensions,
  while the sequence on the bottom relates to the mixed form of the
  Laplacian.

  We introduce the sequences in two dimensions and afterwards will
  focus our arguments on the more general case of three dimensions
  again. Specialization to two dimensions are straight forward.
\end{remark}

\begin{Notation}{hlambda-2d}
  In two dimensions, we consider the de Rham sequences
  \begin{gather}\minCDarrowwidth20pt
    \label{eq:derham:8}
    \begin{CD}
      \R
      @>{\subset}>> H^1(\domain)
      @>{\nabla}>> \Hcurl(\domain)
      @>{\curl}>> L^2(\domain)
      @>>> 0
      \\
      @.
      @A{\cong}AA
      @A{\cong}AA
      @A{\cong}AA
      \\
      \R
      @>{d}>> H\Lambda^0(\domain)
      @>{d}>> H\Lambda^1(\domain)
      @>{d}>> H\Lambda^2(\domain)
      @>>> 0
      \\
      @.
      @V{\cong}VV
      @V{\cong}VV
      @V{\cong}VV
      \\
      \R
      @>{\subset}>> H^1(\domain)
      @>{\curl}>> \Hdiv(\domain)
      @>{\div}>> L^2(\domain)
      @>>> 0,
    \end{CD}
  \end{gather}
\end{Notation}

\begin{Notation}{hlambda-norm}
  The spaces $H\Lambda^k(\domain)$ are Hilbert spaces with the inner product
  \begin{gather}
    \scal(u,v)_{H\Lambda^k} = \scal(u,v)_{L^2} + \scal(d u, d v)_{L^2}.
  \end{gather}
\end{Notation}

The value of this notation lies in the following theorem by de Rham,
which describes the relation between the elements of the sequence. It
is cited here without proof.

\begin{Theorem}{de-rham}
  Assume the domain $\domain$ is Lipschitz.  If $\domain$ is simply
  connected, the sequences in equations~\eqref{eq:derham:9}
  and~\eqref{eq:derham:8} are exact, that is, there holds
  \begin{gather}
    \label{eq:derham:7}
    \ker {d_{k+1}} = \range{d_k}.
  \end{gather}
  If it is not simply connected, the codimension of $\range{d_k}$ in
  $\ker{d_{k+1}}$ is finite. In particular, in both cases,
  $\range{d_k}$ is closed in $H\Lambda^{k+1}(\domain)$.
\end{Theorem}

So far, we have not considered boundary conditions. The next lemma,
which is again stated without proof, indicates that the properties of
the de Rham complex are inherited, if the appropriate boundary
conditions are applied to each space, namely, function values in
$H^1$, tangential traces in $\Hcurl$, and normal traces in
$\Hdiv$. The last restriction from $L^2$ to $L^2_0$ is not a boundary
condition, but it is the compatibility condition implied by the Gauss
theorem on $\Hdiv$.

\begin{Lemma}{hlambda-0}
  The bounded Hilbert cochain complex
  \begin{gather}\minCDarrowwidth20pt
    \begin{CD}
      0
      @>{d}>> H\Lambda^0_0(\domain)
      @>{d}>> H\Lambda^1_0(\domain)
      @>{d}>> H\Lambda^2_0(\domain)
      @>{d}>> H\Lambda^3_0(\domain)
      @>>> 0
      \\
      @.
      @V{\cong}VV
      @V{\cong}VV
      @V{\cong}VV
      @V{\cong}VV
      \\
      0
      @>>> H^1_0(\domain)
      @>{\nabla}>> \Hcurl_0(\domain)
      @>{\curl}>> \Hdiv_0(\domain)
      @>{\div}>> L^2_0(\domain)
      @>>> 0,
    \end{CD}
  \end{gather}
  has the same properties as stated for the Hilbert complex without
  boundary conditions.
\end{Lemma}

% \begin{Example}{not-simply-connected}

% \end{Example}

\begin{remark}
  The complex does not start with $\R$ on the left, but with zero,
  since the constant functions are not members of $H^1_0(\domain)$.

  On the other hand, we could have replaced the right end of the
  complex by
  \begin{gather*}
    L^2(\domain) \xrightarrow{\frac1{\abs{\domain}}\int} \R,
  \end{gather*}
  where the arror is the mean value operator.
\end{remark}

\begin{Theorem}{div-curl-well-posed}
  The Maxwell problem in \blockref{Definition}{Maxwell-mixed-0} is
  well posed.
\end{Theorem}

\begin{proof}
  We have to show the inf-sup condition and the ellipticity of the
  curl-curl bilinear form. Let us introduce
  \begin{gather*}
    a(u,v) = \form(\curl u, \curl v),
    \qquad
    b(v,q) = \form(v,\nabla q).
  \end{gather*}
  From the fact that the de Rham complex starts with zero, we obtain
  that the kernel of the gradient is zero. Thus, for any $q\in
  H^1_0(\domain)\setminus\{0\}$, we have $v = \nabla q \neq 0$ and
  $\norm{v}_{\Hcurl} = \norm{v}_{L^2} \le \norm{q}_{H^1}$. Thus, the
  inf-sup condition holds.

  We show now that $a(.,.)$ is elliptic on $\ker B$. From the
  definition of $b(.,.)$, we deduce that
  $\ker B \perp \nabla H^1_0(\domain) = \ker A$. Thus, $A$ is an
  isomorphism between $\ker B$ and its dual, and consequently
  elliptic.
\end{proof}

\begin{Problem}{darcy-derham}
  Prove well-posedness for the Darcy problem using the de Rham complex
  for proving \blockref{Lemma}{darcy-reduced-wellposed} and
  \blockref{Lemma}{darcy-infsup}.
\begin{solution}
From the last step
 \begin{gather}\minCDarrowwidth20pt
    \begin{CD}
      \Hdiv_0(\domain)
      @>{\div}>> L^2_0(\domain)
      @>>> 0,
    \end{CD}
  \end{gather}
we deduce $L_0^2(\Omega)=\range{\nabla\cdot}$. In particular, this means
that for all $q\in L_0^2(\Omega)$ there exists $v\in H_0^{\text{div}}$ such that
$\nabla \cdot v=q$ and $\norm{v}_{H^{\text{div}}}\leq C \norm{q}_0$.
Hence, it holds the estimate
\begin{align*}
\inf_{q\in Q}\sup_{v\in V}\frac{(\nabla \cdot v, q)}{\norm{q}_Q\norm{v}_V}
  \geq \inf_{q\in Q} \frac{\norm{q}_0}{\norm{v}_{H^{\text{div}}}}\geq C.
\end{align*}
where $q = \nabla \cdot v$. Ellipticity of the bilinear form is obvious
\begin{align*}
  \norm{u}_{H^{\text{div}}}=\norm{u}_0 \quad \forall u\in \ker B.
\end{align*}
\end{solution}
\end{Problem}

\section{Polynomial complexes for simplicial meshes}

\begin{intro}
  We have already seen that adding $x\P_k$ to the space $\P_k^d$, we
  obtain a surjective divergence operator from the Raviart-Thomas
  element to the pressure space $\P_k$. In this section, we see that
  there is a general principle behind this concept and it can be
  extended to the curl and gradient operators.
\end{intro}

\begin{Notation}{pk-complex}
  The homogeneous polynomial spaces $\breve\P_k$ form the cochain complex
  \begin{gather}\minCDarrowwidth15pt
    \begin{CD}
      \R
      @>{d}>> \breve\P_r\Lambda^0
      @>{d}>> \breve\P_{r-1}\Lambda^1
      @>{d}>> \breve\P_{r-2}\Lambda^2
      @>{d}>> \breve\P_{r-3}\Lambda^3
      @>{d}>> 0
      \\
      @.
      @V{\cong}VV
      @V{\cong}VV
      @V{\cong}VV
      @V{\cong}VV
      \\
      \R
      @>{\subset}>> \breve\P_r
      @>{\nabla}>> \breve\P_{r-1}^3
      @>{\curl}>> \breve\P_{r-2}^3
      @>{\div}>> \breve\P_{r-3}
      @>>> 0,
    \end{CD}
  \end{gather}
  and $d_{k+1}\circ d_k = 0$.
\end{Notation}

\begin{remark}
  Since the polynomial space $\P_r$ is the direct sum
  \begin{gather*}
    \P_r = \bigoplus_{s=0}^r \breve\P_s,
  \end{gather*}
  the homogeneous polynomial complex above can be extended to a
  general polynomial complex in a straightforward way.
\end{remark}

\subsection{The Koszul complex}

\begin{Definition}{Koszul-complex}
  The homogeneous \define{Koszul complex} is a polynomial complex of
  the form
  \begin{gather}\minCDarrowwidth15pt
    \label{eq:derham:12}
    \begin{CD}
      0
      @<<< \breve \P_r\Lambda^0
      @<{\kappa_1}<< \breve \P_{r-1}\Lambda^1
      @<{\kappa_2}<< \breve \P_{r-2}\Lambda^2
      @<{\kappa_3}<< \breve \P_{r-3}\Lambda^3
      @<<< 0
    \end{CD}.
  \end{gather}
  The \define{Koszul differential} is defined such that
  \begin{gather}
    \label{eq:derham:13}
    \begin{aligned}
      \kappa_1\omega &= x\cdot\omega & \omega&\in \P_s\Lambda^1,\\
      \kappa_2\omega &= -x\times\omega & \omega&\in \P_s\Lambda^2,\\
      \kappa_3\omega &= x\omega & \omega&\in \P_s\Lambda^3,
    \end{aligned}
  \end{gather}
  and there holds
  \begin{gather}
    \label{eq:derham:14}
    \kappa\circ\kappa = \kappa_{k+1}\circ\kappa_k = 0.
  \end{gather}
\end{Definition}

Note that the ``Koszul differential'' increases the polynomial order
and lowers the order of the form, thus acts in the opposite way of the
usual differential $d$.

\begin{Lemma}{kd-plus-dk}
  For $\omega\in \breve \P_r\Lambda^k$ there holds
  \begin{gather}
    \label{eq:derham:15}
    \bigl(d\kappa+\kappa d\bigr)\omega = (r+k) \omega.
  \end{gather}
\end{Lemma}

\begin{proof}
  Since we are not using differential form technology, we prove this
  for each $k$ directly. For $k=0$, we have $\kappa\omega = 0$, thus
  we have to show
  \begin{gather*}
    \kappa d\omega = r\omega.
  \end{gather*}
  Due to linearity of $\kappa$ and $d$, it suffices to prove the
  result for $\omega = p=x_1^ax_2^bx_3^c$. We note that $dp/d_{x_1} =
  a/x_1 p$ and $d(x_1 p)/d_{x_1} = (a+1) p$ and analogue for the other
  coordinates.
  \begin{gather*}
    \kappa_1 d_0\omega = x\cdot \nabla p = x\cdot
    \begin{pmatrix}
      a/x_1\\b/x_2\\c/x_3
    \end{pmatrix}p
    = (a+b+c)p.
  \end{gather*}
  The second easy case is $k=3$ such that $d\omega = 0$. Let again
  $\omega = p$ to obtain
  \begin{gather*}
    d_2\kappa_3 \omega = \div(xp) = \div
    \begin{pmatrix}
      x_1 p \\x_2 p \\x_3 p
    \end{pmatrix}
    = (a+1+b+1+c+1) p = (r+3) \omega.
  \end{gather*}
  For the two vector valued cases, we note that it suffices to prove
  the result for $\omega = (p,0,0)^T$ and to note that the results for
  nonzero second and third component follow suite. Thus, for $k=1$
  \begin{multline*}
    \nabla (x\cdot \omega) - x\times \curl \omega
    = \nabla(x_1 p) - x\times
    \begin{pmatrix}
      0\\c/x_3 \\ -b/x_2
    \end{pmatrix}p
    \\
    =
    \begin{pmatrix}
      a+1 \\ bx_1/x_2\\ cx_1/x_3
    \end{pmatrix}p
    +
    \begin{pmatrix}
      b+c \\ -bx_1/x_2\\cx_1/x_3
    \end{pmatrix}p
    =
    \begin{pmatrix}
      a+b+c+1 \\0\\0
    \end{pmatrix}p
    = (r+1)\omega.
  \end{multline*}
  Finally, for $k=2$
  \begin{multline*}
    \curl(-x\times \omega) + x \div \omega
    = \curl
    \begin{pmatrix}
      0 \\ -x_3 \\ x_2
    \end{pmatrix}p
    +
    \begin{pmatrix}
      x_1 a/x_1\\x_2 a/x_1\\x_3 a/x_1\\
    \end{pmatrix}p
    \\=
    \begin{pmatrix}
      b+1+c+1\\-ax_2/x_1 \\ -a x_3/x_1
    \end{pmatrix}p
    +
    \begin{pmatrix}
      a\\ax_2/x_1\\ax_3/x_1
    \end{pmatrix}p
    =
    \begin{pmatrix}
      a+b+c+2\\0\\0
    \end{pmatrix}p
    = (r+2)\omega.
  \end{multline*}
\end{proof}

\begin{Lemma}{d-kappa-injective}
  The restriction of operator $d$ to $\range \kappa$ is injective and
  vice versa, or equivalently for any polynomial form
  $\omega\in \breve \P_r\Lambda^k$ there holds
  \begin{gather}
    \label{eq:derham:16}
    \begin{aligned}
      d\kappa\omega &= 0 &\Longrightarrow&& \kappa\omega &= 0,\\
      \kappa d\omega &= 0 &\Longrightarrow&& d\omega &= 0.
    \end{aligned}
  \end{gather}
\end{Lemma}

\begin{proof}
  If $r=k=0$, then $\kappa\omega = d\omega = 0$, such that the lemma
  holds trivially. For $r+k\neq 0$, we apply $\kappa$ to
  equation~\eqref{eq:derham:15} to obtain
  \begin{gather*}
    \kappa\omega = \frac1{r+k}
    \bigl(\kappa d\kappa\omega + \kappa^2d\omega\bigr)
    = \frac1{r+k}\kappa d\kappa\omega.
  \end{gather*}
  Thus, we have proven $d\kappa\omega=0$ implies $\kappa\omega=0$. The
  second implication is proven by applying $d$ to~\eqref{eq:derham:15}.
\end{proof}

\begin{Theorem}{polynomial-exact}
  The polynomial de Rham complex and the Koszul complex are exact for
  $r>3$. Furthermore for $r+k>0$, there holds
  \begin{gather}
    \label{eq:derham:17}
    \breve \P_r\Lambda^k = \kappa \breve\P_{r-1}\Lambda^{k+1}
    \oplus d\breve\P_{r+1}\Lambda^{k-1}.
  \end{gather}
\end{Theorem}

\begin{proof}
  We already know $\range{\kappa_{k-1}} \subset \ker{\kappa_k}$. Thus,
  it remains to show the opposite inclusion. Let therefore $\omega\in
  \breve \P_r\Lambda^k$ such that $\kappa\omega=0$. Then,
  \begin{gather*}
    \omega = \frac1{r+k} (d\kappa\omega+\kappa d\omega)
    = \frac1{r+k} \kappa d\omega =: \kappa\eta
  \end{gather*}
  with $\eta \in \breve\P_{r-1}\Lambda^{k+1}$. Thus,
  $\omega\in \range{\kappa_{k-1}}$. Again, the proof for the de Rham
  complex is obtained by replacing $\kappa$ by $d$.

  In order to see that $\breve \P_r\Lambda^k$ is the sum of the two
  spaces, we let for arbitrary $\omega\in \breve \P_r\Lambda^k$
  \begin{gather*}
    \eta = \frac1{r+k} d\omega \in \breve\P_{r-1}\Lambda^{k+1},
    \qquad
    \mu = \frac1{r+k} \kappa\omega \in \breve\P_{k+1}\Lambda^{k-1}.
  \end{gather*}
  By equation~\eqref{eq:derham:15}, we have
  $\omega = \kappa\eta + d\mu$. It remains to show that the
  intersection of the spaces is zero. Therefore, let $\omega$ be
  chosen from the intersection. Then, $\omega = \kappa\eta = d \mu$
  and
  \begin{gather*}
    (r+k)\omega = d\kappa \omega + \kappa d \omega
    = d \kappa^2 \eta + \kappa d^2 \mu = 0.
  \end{gather*}
\end{proof}

\begin{Corollary}{pk-complexes}
  \blockref{Theorem}{polynomial-exact} holds as well for the
  polynomial complexes
  \begin{gather}\minCDarrowwidth15pt
    \begin{CD}
      0
      @>>> \P_r\Lambda^0
      @>{d}>> \P_{r-1}\Lambda^1
      @>{d}>> \P_{r-2}\Lambda^2
      @>{d}>> \P_{r-3}\Lambda^3
      @>>> 0
    \end{CD},
  \end{gather}
  and
  \begin{gather}\minCDarrowwidth15pt
    \begin{CD}
      \R
      @<<< \P_r\Lambda^0
      @<{\kappa}<< \P_{r-1}\Lambda^1
      @<{\kappa}<< \P_{r-2}\Lambda^2
      @<{\kappa}<< \P_{r-3}\Lambda^3
      @<<< 0
    \end{CD}.
  \end{gather}
\end{Corollary}

\begin{proof}
  This is due to the fact that the polynomial spaces $\P_r$ are the
  direct sums of homogeneous polynomial space $\breve\P_s$.
\end{proof}

\begin{Definition}{pk-plus}
  The polynomial space of $k$-forms $\P_r^+\Lambda^k$ is defined as
  \begin{gather}
    \P_r^+\Lambda^k = \P_r\Lambda^k \oplus \kappa \P_r\Lambda^{k+1}.
  \end{gather}
  It is also referred to as $\P_{r+1}^-\Lambda^k$. Furthermore,
  \begin{gather*}
    \P_r^+\Lambda^0 = \P_{r+1}\Lambda^0,
    \qquad
    \P_r^+\Lambda^d = \P_r\Lambda^d.
  \end{gather*}
\end{Definition}

\begin{remark}
  We have used the construction principle
  \begin{gather*}
    \P_r\Lambda^k = \P_{r-1}\Lambda^k \oplus \breve \P_r\Lambda^k.
  \end{gather*}
  Using its decomposition, we obtain
  \begin{gather*}
    \P_r\Lambda^k =
    \bigoplus_{s=1}^{r-1}\kappa \breve\P_{s-1}\Lambda^{k+1}
    \bigoplus_{s=1}^{r-1} d\breve\P_{s+1}\Lambda^{k-1}
    \oplus \kappa \breve\P_{r-1}\Lambda^{k+1}
    \oplus d\breve\P_{r+1}\Lambda^{k-1}.
  \end{gather*}
  If we leave out the last factor, we get the new space
  $\P_{r-1}^+\Lambda^k$.
\end{remark}

\begin{Lemma}{pk-plus-d}
  If $\omega\in \P_r^+\Lambda^k$ and $d\omega=0$, then
  $\omega\in\P_r\Lambda^k$.
\end{Lemma}

\begin{proof}
  Let $\omega = \omega_1 + \kappa\eta$ with $\omega_1\in\P_r\Lambda^k$
  and $\eta\in \breve\P_r\Lambda^{k+1}$. Then,
  $d\omega_1\in\P_{r-1}\Lambda^{k+1}$ and
  $d\kappa\eta\in \breve\P_r\Lambda^{k+1}$. Therefore,
  $d\omega_1 = d\kappa\eta = 0$. By
  \blockref{Lemma}{d-kappa-injective}, $\kappa\eta=0$, such that
  $\omega=\omega_1$.
\end{proof}

% AFW 2006 Lemma 3.8
\begin{Lemma}{pr-pr-plus}
  For $r\ge 1$ and $0\le k < d$ there holds
  \begin{gather}
    d\P_{r}^+\Lambda^k \subset d\P_{r+1}\Lambda^k
    \subset \P_r\Lambda^{k+1}
    \subset \P_r^+\Lambda^{k+1}.
  \end{gather}
  The following four mappings $d$ have the same kernel:
  \begin{gather}
    \begin{aligned}
      d\colon \P_r\Lambda_k &\to \P_{r-1}\Lambda^{k+1}
      &
      d\colon \P_r^+\Lambda_k &\to \P_{r}\Lambda^{k+1}
      \\
      d\colon \P_r\Lambda_k &\to \P_{r-1}^+\Lambda^{k+1}
      &
      d\colon \P_r^+\Lambda_k &\to \P_{r}^+\Lambda^{k+1}
    \end{aligned}
  \end{gather}
  The following four mappings $d$ have the same range:
  \begin{gather}
    \begin{aligned}
      d\colon \P_r\Lambda_k &\to \P_{r-1}\Lambda^{k+1}
      &
      d\colon \P_{r-1}^+\Lambda_k &\to \P_{r-1}\Lambda^{k+1}
      \\
      d\colon \P_r\Lambda_k &\to \P_{r-1}^+\Lambda^{k+1}
      &
      d\colon \P_{r-1}^+\Lambda_k &\to \P_{r-1}^+\Lambda^{k+1}
    \end{aligned}
  \end{gather}
\end{Lemma}

\begin{proof}
  The first statement follows from the inclusions of $\P_r$ and
  $\P_r^+$. The horizontal equality of the second statement follows
  from \blockref{Lemma}{pk-plus-d}. The vertical identities from the
  decomposition~\eqref{eq:derham:17}. For the last set of identities,
  we observe that by construction
  \begin{gather*}
    \P_r\Lambda^k = \P_{r-1}^+\Lambda^k \oplus d \P_{r+1}\Lambda^{k-1}.
  \end{gather*}
  Thus, $d\P_r\Lambda^k = d\P_{r-1}^+\Lambda^k\subset \P_{r-1}\Lambda^{k+1}$.
\end{proof}

\begin{Theorem}{dimension-pr-lambda}
  Let $r\ge 0$ and $1\le k \le d$. Then,
  \begin{gather}
    \begin{split}
      \dim \kappa \breve P_r\Lambda^k(\R^d)
      & = \dim d \breve P_{r+1}\Lambda^{k-1}(\R^d)
      \\
      &= \binom{d+r}{d-k}\binom{r+k-1}{k-1}.
    \end{split}
  \end{gather}
\end{Theorem}

\begin{proof}
  First, we prove the equality of the two dimensions by applying $\kappa$
  to equation~\eqref{eq:derham:17}, yielding
  \begin{gather*}
    \kappa \breve P_r\Lambda^k(\R^d)
    = \kappa d \breve P_{r+1}\Lambda^{k-1}(\R^d).
  \end{gather*}
  By \blockref{Lemma}{d-kappa-injective}, the two spaces are
  isomorphic and the equality holds.

  The dimension formula is proven first for $r=0$ and $k\ge 1$. The
  Koszul operator is injective on $\P_0\Lambda^K(\R^d)$ since the
  first factor in equation~\eqref{eq:derham:17} vanishes. It is
  also injective on $\breve P_r\Lambda^d(\R^d)$ for $r\ge 0$.

  For all other combinations of $r$ and $k$ it is proven by induction
  over $k$. For $k=d$,
  \begin{gather*}
    \dim \breve\P_r\Lambda^d(\R^d) = \dim\breve\P_r(\R^d)
    = \binom{d+r-1}{d-1}.
  \end{gather*}
  For $k<d$, we assume the formula proven for $k+1$. We have
% Move this to an earlier point or an appendix
  \begin{gather*}
    \breve P_r\Lambda^k(\R^d) = \binom{d+r-1}{d-1}\binom{d}{k}.
  \end{gather*}
  Now, the dimension formula
  \begin{gather*}
    \dim \range \phi = \dim V - \dim ker \phi,
  \end{gather*}
  yields
  \begin{gather*}
    \dim\kappa\breve \P_r\Lambda^k(\R^d) =
    \dim\breve \P_r\Lambda^k(\R^d)
    - \dim\kappa\breve \P_{r-1}\Lambda^{k+1}(\R^d),
  \end{gather*}
  where we have used the exactness of the Koszul complex.
  Using the induction hypothesis yields by the binomial identity
% Olkhovskiy
  \begin{align*}
    \dim\kappa\breve \P_r\Lambda^k(\R^d) 
    &= \binom{d+r-1}{d-1}\binom{d}{k} - \binom{d+r-1}{d-k-1}\binom{r+k-1}{k}
    \\
    &= \frac{(d+r-1)!{\color{green}d!}}{{\color{green}(d-1)!}{\color{purple}r!}k!{\color{blue}(d-k)!}}
      - \frac{(d+r-1)!{\color{red}(r+k-1)!}}{{\color{blue}(d-k-1)!}
      {\color{red}(r+k)!}k!{\color{purple}(r-1)!}}
    \\
    &=
      \frac{(d+r-1)!{\color{green}d}{\color{red}(r+k)}-{\color{blue}(d-k)}(d+r-1)!{\color{purple}r}}
      {{\color{purple}r!}k!{\color{blue}(d-k)!}{\color{red}(r+k)}}
    \\
    &= \frac{(d+r-1)!\bigl(d(r+k)-(d-k)r\bigr)}{r!k!(d-k)!(r+k)}
    \\
    &= \frac{(d+r)!}{r!(k-1)!(d-k)!(r+k)}
    \\
    &= \binom{d+r}{d-k}\binom{r+k-1}{k-1}.
  \end{align*}
\end{proof}

\subsection{Degrees of freedom and bases for simplicial meshes}

\begin{intro}
  After having studied the properties of the de Rham complex and the
  Koszul complex of polynomial spaces, we continue like with standard
  finite elements and define a basis of shape functions and sets of
  degrees of freedom dual to this basis. Note that the following
  definition subsumes the definitions of conforming finite elements
  for $H^1$, $\Hcurl$ and $\Hdiv$ in a single statement.
\end{intro}

\begin{Definition}{mesh-pk}
  Given a space of polynomial forms
  $\P_r\Lambda^k=\P_r\Lambda^k(\R^d)$, we define the space of finite
  element polynomial forms on a mesh $\mesh_h$ covering the domain
  $\domain\subset\R^d$ as
  \begin{gather}
    \P_r\Lambda^k(\mesh) = \bigl\{
    \omega \in H\Lambda^k \big|
    \;\forall \cell\in\T\colon \omega_{|\cell} \in \P_r\Lambda^k
    \bigr\}.
  \end{gather}
\end{Definition}

\begin{intro}
  The degrees of freedom have to be designed such that they guarantee
  the necessary continuity between cells. To this end, we have to
  study the traces of polynomial forms on the boundaries (called
  subsimplices below) of the simplex $\cell$. Then, we can start
  decomposing degrees of freedom and node values such that they can be
  allocated to these subsimplices.
\end{intro}

\subsubsection{Geometric structure of simplices}

\begin{Definition}{spanned-simplex}
  Let $x_0,\dots,x_k$ for $k\le d$ be a set of $k+1$ points in
  $\R^d$. Then, we call the set of convex combinations of these points
  the $k$-simplex $f$ spanned by $\{x_0,\dots,x_k\}$.
\end{Definition}


\begin{Definition}{subsimplices}
  Let $\cell$ be the simplex in $\R^d$ spanned by the points
  $x_0,\dots,x_d$. Then, every ascending subset
  $\sigma \subset \{0,\dots,d\}$ of length $k+1$ defines a
  $k$-dimensional \define{subsimplex} of $\cell$ denoted as $f_\sigma$.

  The set of all subsimplices of $\cell$, including $\cell$ itself is
  called $\Delta(\cell)$. The set of all $k$-dimensional subsimplices
  is $\Delta_k(\cell)$.
\end{Definition}

\begin{example}
  A $d$-dimensional simplex $\cell$ has $\binom{d+1}{k+1}$
  subsimplices of dimension $k$.

  The one-dimensional simplex $[x_0,x_1]$ has two subsimplices of
  dimension zero, namely the two points $x_0$ and $x_1$.

  The triangle spanned by the points $x_0, x_1, x_3$ has three
  one-dimensional subsimplices (edges) and three zero-dimensional
  subsimplices (vertices).

  The tetrahedron spanned by the points $x_0,\dots,x_3$ has
  \begin{itemize}
  \item 4 triangular faces,
  \item 6 edges,
  \item 4 vertices.
  \end{itemize}
\end{example}

\subsubsection{Geometric decomposition of $\P_r(\cell)$}

\begin{remark}
  For a simplex $\cell\subset\R^d$, the barycentric coordinates are
  the uniquely determined linear interpolating polynomials such that
  \begin{gather*}
    \lambda_i(x_j) = \delta_{ij}.
  \end{gather*}
  Then,
  \begin{gather*}
    \cell = \biggl\{ x = \sum_{i=0}^d\lambda_i\bigg\vert
    \lambda_i \ge 0,\quad\sum_{i=0}^d\lambda_i = 1\biggr\}.
  \end{gather*}

  Let $f=f_\sigma$ be the $k$-dimensional subsimplex spanned by the
  points $x_{\sigma_0},\dots,x_{\sigma_k}$. Then, the linear
  polynomials $\lambda_{\sigma_1},\dots,\lambda_{\sigma_k}$ form a set
  of barycentric coordinates for $f_\sigma$, that is,
  \begin{gather}
    \begin{split}
      f_\sigma &= \bigl\{x\in\cell \big\vert
      \lambda_j=0 \text{ for } j\not\in\sigma\bigr\}.
      \\
      &= \biggl\{ x = \sum_{i\in\sigma}\lambda_i\bigg\vert
    \lambda_i \ge 0,\quad\sum_{i\in\sigma}\lambda_i = 1\biggr\}.
    \end{split}
  \end{gather}
\end{remark}

\begin{remark}
  When we introduced barycentric coordinates in order to define
  standard shape functions on simplices, we generated a basis for
  $\P_r(\R^d)$ by selecting polynomials of the $\lambda_i$. Closer
  inspection reveals that these polynomials were
  homogeneous. Therefore, we defined an isomorphism
  \begin{gather}
    \breve \P_k(\R^{d+1}) \equiv \P_k(\R^d),
  \end{gather}
  which reads: for every $p\in \P_k(\R^d)$ there is
  $q\in\breve\P_k(\R^{d+1})$ such that
  \begin{gather*}
    p(x_1,\dots,x_d) = q(\lambda_0,\dots,\lambda_d).
  \end{gather*}
% Argue why isomorphism: count?
\end{remark}

\begin{Definition}{pr-f}
  For each $k$-dimensional subsimplex $f_\sigma$ of $\cell$ with
  $\sigma = \sigma_0,\dots,\sigma_k$, the space
  $\P_r(f_\sigma) \equiv \breve\P_r(\R^{k+1})$ is defined as
  \begin{gather}
    \P_r(f_\sigma) = \bigl\{
    q(\lambda_{\sigma_0},\dots,\lambda_{\sigma_k})\big\vert
    q\in\breve \P_r(\R^{k+1})\bigr\}.
  \end{gather}
  The \putindex{bubble function} associated with $f_\sigma$ is
  \begin{gather}
    b_{f\sigma} = \lambda_{\sigma_0}\cdots\lambda_{\sigma_k}.
  \end{gather}
  The \define{extension operator} $E_{f_\sigma\to\cell}$ is defined as
  \begin{gather}
    \begin{split}
      E_{f_\sigma\to\cell}\colon \P_r(f_\sigma) &\to \P_r(\R^d),\\
      p(\lambda_0,\dots,\lambda_d) &= q(\lambda_{\sigma_0},\dots,\lambda_{\sigma_k}),
    \end{split}
  \end{gather}
  where $q$ is chosen as in the definition of $\P_r(f_\sigma)$.
\end{Definition}

\begin{Lemma}{subsimplex-polynomials}
  Every function in $\P_r(f)$ vanishes on every subsimplex $g$ which
  is disjoint from $f$.

  The bubble function $b_f$ vanishes on every subsimplex not containing $f$.
\end{Lemma}

\begin{Problem}{subsimplex-polynomials}
  Show: $\P_r(f_\sigma)$ is isomorphic to $\P_r(\R^k)$. Prove
  \blockref{Lemma}{subsimplex-polynomials}.
\begin{solution}
  Since $\P_r(f_\sigma)$ is isomorphic to $\breve\P_r(\R^{k+1})$ and
  $\P_r(f_\sigma)$ is a vector space
  all we have to do is to show that the dimensions are equal.
  In fact, $\dim \P_r(\R^k) = \binom{r+k}{k}$
  (show by distributiung separators) and
  $\dim \breve\P_r(\R^k) = \binom{r+k-1}{k-1}$.
  Thus, $\dim \breve\P_r(\R^{k+1}) = \binom{r+k}{k} = \dim \P_r(\R^k)$
  and the two spaces are isomorphic.

  Let $g$ be a subsimplex that is disjoint from $f$.
  \begin{align*}
      f_\sigma &= \bigl\{x\in\cell \big\vert
      \lambda_j=0 \text{ for } j\not\in\sigma\bigr\}.
      \\
      &= \biggl\{ x = \sum_{i\in\sigma}\lambda_i\bigg\vert
    \lambda_i \ge 0,\quad\sum_{i\in\sigma}\lambda_i = 1\biggr\}.
  \end{align*}
  Then $\sigma_f$ and $\sigma_g$ are disjoint and in particular
  $\lambda_i = 0$ for all $i\in \sigma_f$ in the decomposition
  $g \ni x = \sum_i \lambda_i(x)$. Thus, $p\in \P_r(f)$
  is identified by $q(\lambda_{\sigma_0},\dots,\lambda_{\sigma_k})$
  which vanishes for all $x \in g$.

  Let $g$ be a subsimplex not containing $f$. Then, $\sigma_f\setminus \sigma_g$ is non-empty.
  In the decomposition $g\ni x = \sum_i\lambda_i$ such that $\lambda_i \ge 0,\quad\sum_i\lambda_i = 1$ at most
  the $\lambda_i$ ($i\in\sigma_f$) for $i\in\sigma_f\cap\sigma_g$ are non-zero. Due to to our assumption
  $\sigma_f\cap\sigma_g$ is a proper subset of $\sigma_f$ and hence there exist for each $x \in f\cap g$
  a $i \in \sigma_f$ such that $\lambda_i=0$. This implies $b_{f_\sigma}\equiv 0$ on $g$.
\end{solution}
\end{Problem}

\begin{Example}{h1-moment-dofs}
  \begin{center}
    \includegraphics[width=.3\textwidth]{fig/p1-p}
    \includegraphics[width=.3\textwidth]{fig/p2-p}
    \includegraphics[width=.3\textwidth]{fig/p3-p}
  \end{center}
  Unisolvent interpolation conditions for $\P_r(\cell)$
  \begin{xalignat*}3
    u(f) &= 0 &&& \dim f &= 0\\
    \form(u,q)_f &= 0 & q&\in \P_{r-2}(f) & \dim f &= 1 \\
    \form(u,q)_f &= 0 & q&\in \P_{r-3}(f) & \dim f &= 2 \\
    &\vdots && \vdots && \vdots
  \end{xalignat*}
\end{Example}

We are now generalizing and formalizing this example in order to
derive a geometric decomposition of $\P_r(\cell)$ and its dual.

\begin{Definition}{v-of-f}
  For every $f\in\Delta(\cell)$%
  %with $\sigma=\{\sigma_0,\dots,\sigma_k\}$
  , we define
  $V(f) \subset \P_r(\cell)$  for $\dim f>0$ as
  \begin{gather}
    V(f) = \bigl\{ p = E_{f\to\cell} b_f q \big\vert
    \;q \in \P_{r-\dim f -1}(f) \bigr\},
  \end{gather}
  and for $\dim f=0$
  \begin{gather}
    V(f) = \bigl\{ \lambda_i^r \big\vert
    \;f = \{x_i\}\bigr\}.
  \end{gather}
\end{Definition}

\begin{Definition}{w-of-f}
  For every $f\in\Delta(\cell)$, we define
  $W(f) \subset \P_r(\cell)^*$ for $\dim f>0$ as
  \begin{gather}
    W(f) = \bigl\{\phi(p) = \form(p,q)_f\big\vert
    \;q\in\P_{r-\dim f-1}(f) \bigr\},
  \end{gather}
  and for $\dim f=0$
  \begin{gather}
    W(f) = \bigl\{\phi(p)= p(x_i) \big|
    \;f=\{x_i\}
    \bigr\}.
  \end{gather}
\end{Definition}

\begin{Lemma}{pr-geometric}
  There holds
  \begin{gather}
    \P_r(\cell) = \bigoplus_{f\in\Delta(\cell)}V(f),
    \qquad
    \P_r(\cell)^* = \bigoplus_{f\in\Delta(\cell)}W(f).
  \end{gather}
\end{Lemma}

\begin{proof}
  We begin to show that
  \begin{gather*}
    \P_r(\cell) = \bigoplus_{f\in\Delta(\cell)}V(f).
  \end{gather*}
  First, we note that for any $f\in\Delta(\cell)$ every function in $V(f)$
  is also in $\P_r(\cell)$.  For $\dim f=0$, that is, $f=\{x_i\}$ for some
  vertex $x_i$, the only homogeneous polynomial of order $r$ is $\lambda_i^r$.

  For $\dim f > 0$ we have by the first statement of
  \blockref{Lemma}{subsimplex-polynomials}, that the spaces $V(f)$
  where $f$ is a vertex are disjoint. By the second statement of the
  same lemma, the spaces $V(f)$ for all $f$ with equal dimension are
  disjoint. Therefore, the sum
  \begin{gather*}
    V_d(\cell) = \sum_{k=0}^{d-1} \sum_{f\in \Delta_k(\cell)} V(f),
  \end{gather*}
  is direct. But, $V(\cell) \cap V_d(\cell) = \{0\}$, since all elements in
  $V(\cell)$ contain a bubble function factor. Therefore,
  \begin{gather*}
    \bigoplus_{f\in\Delta(\cell)}V(f) \subset \P_r(\cell).
  \end{gather*}
  We conclude by showing that dimensions on both sides are equal.
  On the right, we use
  \begin{gather*}
    \dim \P_r(\R^d) = \binom{r+d}{r} = \frac{(r+d)!}{d!r!}
  \end{gather*}
  On the left, we have
  \begin{multline*}
    \dim \bigoplus_{f\in\Delta(\cell)}V(f) =
    \sum_{k=0}^{d} \binom{d+1}{k+1} \binom{r+k}{k}
    \\
    = \frac{(d+1)!}{r!}
    \sum_{k=0}^{d} \frac{1}{(k+1)!(d-k)!} \frac{(r+k)!}{k!}.
  \end{multline*}

% Finish this!

  It remains to show the decomposition for $\P_r(\cell)^*$. To this
  end, we first notice that for any $f\in\Delta(\cell)$ there holds
  $\dim W(f) = \dim V(f)$ by their definition. Furthermore, for
  $p\in V(f)$ there holds
  \begin{gather*}
    \Bigl(\phi(p) = 0 \quad\forall \phi\in W(f)\Bigr)
    \quad\Rightarrow\quad
    p=0.
  \end{gather*}
  Thus, for $p\in \P_r(\cell)$ there holds
  \begin{gather*}
    \Bigl(\phi(p) = 0 \quad\forall \phi\in \sum W(f)\Bigr)
    \quad\Rightarrow\quad
    p=0.
  \end{gather*}
  Consequently,
  \begin{gather*}
    \P_r(\cell)^* = \sum W(f).
  \end{gather*}
  since we have already proven that
  \begin{gather*}
    \dim \P_r(\cell)^* = \sum \dim W(f),
  \end{gather*}
  the sum on the right must be direct.
\end{proof}

\subsubsection{Results for $\P_r\Lambda^k$ and $\P_r^+\Lambda^k$ and applications}

For polynomial differential forms on simplices, we cite the main
results without proof and then discuss their application to $\Hdiv$
and $\Hcurl$.

\begin{Theorem}{decomp-pr-plus}
  Let $k,r\ge 1$. Then, $\P_r^+(\cell)$ admits a geometric decomposition
  \begin{gather}
    \P_r^+\Lambda^k(\cell) = \bigoplus_{f\in\Delta(\cell)} V(f),
    \qquad
    \P_r^+\Lambda^k(\cell)^* = \bigoplus_{f\in\Delta(\cell)} W(f),
  \end{gather}
  where
  \begin{align}
    V(f) \equiv
    \begin{cases}
      0 & \dim f < k\\
      \P_{r+k-\dim f} \Lambda^{\dim f-k}(f) &\text{else}\\
      0 & \dim f > r+k.
    \end{cases}
    \\
    W(f) \equiv
    \begin{cases}
      0 & \dim f < k\\
      \P_{r+k-\dim f} \Lambda^{\dim f-k}(f) &\text{else}\\
      0 & \dim f > r+k.
    \end{cases}
  \end{align}
\end{Theorem}

\begin{Example}{rt-complex-decomp}
  \begin{gather}
    \begin{array}{c|cccccc}
      \dim f
      & \P_r^+\Lambda^0 & \P_{r+1}
      & \P_r^+\Lambda^1 & N^{1e}_r
      & \P_r^+\Lambda^2 & RT_r \\\hline
      3 & \P_{r-3}\Lambda^3 & \P_{r-3} & \P_{r-2}\Lambda^2 & BDM_{r-2} & \P_{r-1}\Lambda^1 & N^{2e}_{r-1} \\
      2 & \P_{r-2}\Lambda^2 & \P_{r-2} & \P_{r-1}\Lambda^1 & BDM_{r-1} & \P_{r}\Lambda^0 & \P_r\\
      1 & \P_{r-1}\Lambda^1 & \P_{r-1} & \P_{r}\Lambda^0   & \P_r  & -- & -- \\
      0 & \R & \R & -- & -- & --& --
    \end{array}
  \end{gather}
  Geometric decomposition of $\P_r^+\Lambda^k$ and their spaces of degrees of freedom.
  \begin{itemize}
  \item [$N^{1e}$] ($\Hcurl$) Nedelec 1st family edge element
  \item [$RT$] ($\Hdiv$) Raviart-Thomas (also Nedelec 1st face in 3D)
  \item [$N^{2e}$] ($\Hcurl$) Nedelec 2nd family edge element
  \end{itemize}
\end{Example}

\begin{Theorem}{decomp-pr}
  Let $k,r\ge 1$. Then, $\P_r(\cell)$ admits a geometric decomposition
  \begin{gather}
    \P_r\Lambda^k(\cell) = \bigoplus_{f\in\Delta(\cell)} V(f),
  \end{gather}
  where
  \begin{gather}
    V(f) \equiv
    \begin{cases}
      0 & \dim f < k\\
      \P_{r+k-\dim f-1}^+ \Lambda^{\dim f-k}(f) &\text{else}\\
      0 & \dim f \ge r+k.
    \end{cases}
  \end{gather}
\end{Theorem}

\begin{Example}{bdm-complex-decomp}
  \begin{gather}
    \begin{array}{c|cccc}
      \dim f
      & \P_r\Lambda^1 & N^{2e}_r
      & \P_r\Lambda^2 & BDM_r \\\hline
      3 & \P_{r-3}^+\Lambda^2 & RT_{r-2} & \P_{r-1}^+\Lambda^1 & N^{1e}_{r-1} \\
      2 & \P_{r-2}^+\Lambda^1 & RT_{r-1} & \P_{r}^+\Lambda^0 & \P_r \\
      1 & \P_{r-1}^+\Lambda^0 & \P_r & --& --
%      0 & \R & \R & -- & --
    \end{array}
  \end{gather}
  Geometric decomposition of $\P_r\Lambda^k$ and their spaces of degrees of freedom.
  \begin{itemize}
  \item [$N^{2e}$] ($\Hcurl$) Nedelec 2nd family edge element
  \item [$BDM$] ($\Hdiv$) Brezzi-Douglas-Marini (also Nedelec 2nd face in 3D)
  \item [$N^{1e}$] ($\Hcurl$) Nedelec 1st family edge element
  \end{itemize}
\end{Example}



\section{The complex of tensor product polynomials}

\begin{Lemma}{qr-complex}
  Tensor product polynomials form the exact sequence
  \begin{gather*}
    \R
    \overset{\subset}{\longrightarrow} \Q_r
    \overset{\nabla}{\longrightarrow}
    \begin{pmatrix}
      \Q_{r,r+1,r+1}\\\Q_{r+1,r,r+1}\\\Q_{r+1,r+1,r}
    \end{pmatrix}
    \overset{\curl}{\longrightarrow}
    \begin{pmatrix}
      \Q_{r+1,r,r}\\\Q_{r,r+1,r}\\\Q_{r,r,r+1}
    \end{pmatrix}
    \overset{\div}{\longrightarrow}
    \Q_r
    \longrightarrow 0,    
  \end{gather*}
\end{Lemma}

\begin{proof}
  First, we show that the differential operators map into the right
  spaces. Let $q\in\Q_{r+1}$ such that
  $q(x) = q_1(x_1) q_2(x_2)q_3(x_3)$ with $q_i\in\Q_{r+1}$. Then
  \begin{gather*}
    \nabla q =
    \begin{pmatrix}
      q_1'q_2q_3\\q_1q_2'q_3\\q_1q_2q_3'
    \end{pmatrix}
    \in
    \begin{pmatrix}
      \Q_{r,r+1,r+1}\\\Q_{r+1,r,r+1}\\\Q_{r+1,r+1,r}
    \end{pmatrix}.
  \end{gather*}
  Similarly, we can compute this directly for $\curl$ and
  $\div$. Since polynomials are differentiable, we have $d^2=0$. It
  remains to show that the sequence is exact, which we will prove at
  the example of $\Hcurl$. Let $u\in \ker{\curl}$,
  \begin{gather*}
    u=
    \begin{pmatrix}
      \phi_1\phi_2\phi_3\\
      \psi_1\psi_2\psi_3\\
      \pi_1\pi_2\pi_3
    \end{pmatrix},
    \qquad
    0 = \curl u =
    \begin{pmatrix}
      \pi_1\pi_2'\pi_3 - \psi_1\psi_2\psi_3'\\
      \phi_1\phi_2\phi_3' - \pi_1'\pi_2\pi_3\\
      \psi_1'\psi_2\psi_3 - \phi_1\phi_2'\phi_3
    \end{pmatrix},
  \end{gather*}
  where each polynomial with index $i$ only depends on
  $x_i$. Furthermore, $\phi_1,\psi_2,\pi_3\in\P_r$ and all other in
  $\P_{r+1}$.  From the continuous de Rham complex, we know that there
  is a function $p$ such that $u=\nabla p$. It remains to show that
  $p\in\Q_{r+1}$. There holds
  \begin{gather*}
    \d_1 p = \phi_1\phi_2\phi_3.
  \end{gather*}
  Thus, we make the ansatz
  \begin{gather*}
    p = \Phi_1\phi_2\phi_3,
  \end{gather*}
  where $\Phi_1\in\P_{r+1}$ is the antiderivative of $\phi_1$. Thus,
  $p\in\Q_{r+1}$ It remains to show that this ansatz is consistent
  with the other two derivatives, thus,
  \begin{gather*}
    p = \Phi_1\phi_2\phi_3 = \psi_1\Psi_2\psi_3 = \pi_1\pi_2\Pi_3.
  \end{gather*}
  Integrating the first component of $\curl u$ with respect to $x_2$
  and $x_3$, we obtain
  \begin{gather*}
    \pi_1\pi_2\Pi_3 = \psi_1\Psi_2\psi_3.
  \end{gather*}
  Doing the same with the second component, we see indeed that the
  function $p$ is consistently defined and thus $u=\nabla p$.
\end{proof}

\begin{Definition}{pr-complex-1d}
  The one-dimensional de Rham complex on the interval $I = [\xi_0,\xi_1]$ and
  its polynomial subcomplex are
  \begin{gather}
    \begin{CD}
    \R
    @>{\subset}>>
    H^1(I) = H\Lambda^0(I)
    @>{\tfrac{d}{dx}}>>
    L^2(I) = H\Lambda^1(I)
    @>>> 0
    \\
    @.
    @A{\subset}AA
    @A{\subset}AA
    \\
    \R
    @>{\subset}>>
    \P_{r+1} = \P_{r+1}\Lambda^0
    @>{\tfrac{d}{dx}}>>
    \P_r = \P_r\Lambda^1
    @>>> 0
    \end{CD}
  \end{gather}
  The degrees of freedom for $\P_{r+1}\Lambda^0$ are
  \begin{gather}
    \begin{matrix}
    \nodal_{0,0}(p) = p(\chi_0),\\
    \nodal_{0,1}(p) = p(\chi_1),
    \end{matrix}\qquad
    \nodal_{1.q}(p) = \int_{I} p q \dx,\quad\forall q\in\P_{r-1}.
  \end{gather}
  The degrees of freedom for $\P_{r}\Lambda^1$ are
  \begin{gather}
    \nodal_{1,q}(p) = \int_{I} p q \dx,\quad\forall q\in\P_{r}.
  \end{gather}
\end{Definition}

\begin{remark}
  The degrees of freedom for $\P_{r+1}\Lambda^0$ are chosen such that
  the finite element function on a subdivision of $I$ is continuous,
  thus ih $H^1$. For $\P_{r}\Lambda^1$, we do not require continuity
  and thus only need interior degrees of freedom.
\end{remark}

\begin{Definition}{tensor-dofs}
  Let
  \begin{gather}
    \nodal_{0,0} p = p(\chi_0),\qquad \nodal_{0,1} p = p(\chi_1), \qquad
    \nodal_{1,i} = \int_I p q_i\dx,
  \end{gather}
  be the degrees of freedom of a one-dimensional element where the
  $q_i$ are a basis for $\P_{r-1}$ and $\P_r$ in case of
  $\P_{r+1}\Lambda^0$ and $\P_{r}\Lambda^1$, respectively. Then, the
  tensor product of these degrees of freedom applied to the function
  $p(x_1,x_2) = p_1(x_1)p_2(x_2)$ is defined as
  \begin{gather}
    \begin{split}
      \nodal_{0,i}\otimes\nodal_{0,j}(p) &= p_1(\chi_i) p_2(\chi_j),\\
      \nodal_{0,i}\otimes\nodal_{1,j}(p) &= \int_I p_1(\chi_i)  p_2(x)q_j(x)\dx,\\
      \nodal_{1,i}\otimes\nodal_{0,j}(p) &= \int_I p_1(x)q_j(x) p_2(\chi_j) \dx,\\
      \nodal_{1,i}\otimes\nodal_{1,j}(p) &= \iint_I p_1(x_1)
      p_2(x_2) \dx_1\dx_2.
    \end{split}
  \end{gather}
\end{Definition}

\begin{Lemma}{2d-tensor-rt-nedelec}
  For the two elements
  \begin{gather}
    RT_r =
    \begin{pmatrix}
      \P_{r+1}\Lambda^0 \otimes \P_{r}\Lambda^1\\
      \P_{r}\Lambda^1 \otimes \P_{r+1}\Lambda^0
    \end{pmatrix},
    \qquad
    N^{1e}_r =
    \begin{pmatrix}
      \P_{r}\Lambda^1 \otimes \P_{r+1}\Lambda^0\\
      \P_{r+1}\Lambda^0 \otimes \P_{r}\Lambda^1      
    \end{pmatrix},
  \end{gather}
  the tensorized degrees of freedom uniquely determine the normal and
  tangential components, respectively, on the face of a square.

  Both elements with their tensor degrees of freedom are unisolvent.
\end{Lemma}

\begin{proof}
  The elements are unisolvent by the following argument: Let
  $\{\phi_i\}$ and $\{\psi_j\}$ be the basis dual to the degrees of
  freedom of $\P_{r+1}\Lambda^0$ or $\P_r \Lambda^1$,
  respectively. Then, (renumbering the degrees of freedom)
  \begin{gather*}
    \nodal_k\otimes\nodal_l(\phi_i\otimes\psi_j) = \delta_{ik}\delta_{jl}.
  \end{gather*}
  Thus, the mapping between tensorized degrees of freedom and
  tensorized basis functions is one-to-one.

  For the Raviart-Thomas element $RT_r$, the normal component is
  $\P_r\Lambda^1$. Take for instance the face $x_1 = \chi_0$. Then,
  the degrees of freedom associated to this face are
  \begin{gather*}
    \nodal_{0,0} \otimes \nodal{1,q} p
    = \int_I p_1(\chi_1) p_2(x_2) q(x_2) \dx_2
    \quad\forall q\in \P_r.
  \end{gather*}
  Since the trace of $p$ on this face is $p_2 \in \P_r$, this
  polynomial is uniquely determined by the degree of freedom.

  The argument for the Nedelec edge element $N^{1e}_r$ follows by
  exchanging tangential and normal component.
\end{proof}

\begin{remark}
  The construction extends to the three-dimensional products.
\end{remark}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
