\usepackage{algpseudocode}
\lstset{language=Python,numbers=left,resetmargins=true,xleftmargin=8pt,basicstyle=\small,numberstyle=\scriptsize}
\usetikzlibrary{svg.path}
\usetikzlibrary{matrix,fit}
\pgfdeclarelayer{bg}
\pgfsetlayers{bg,main}
\excludecomment{solution}
\input{mixed/fig/tikzsettings}

\title{Numerical Linear Algebra}
\author{Guido Kanschat}
\date{\today}

\def\esp#1{V_{#1}}

\input{only}
\begin{document}
\maketitle
\tableofcontents
\include{ortho}
\include{dense-evp}
\include{sparse}
\include{sparse-evp}

\appendix
\chapter{Basics from Linear Algebra}
\section{Vectors, bases, and matrices}

\begin{Definition}{parallel}
  We call two vectors $\vv,\vw$ in a vector space $V$ \define{parallel}, if
  there is a scalar factor $\alpha$ such that $\alpha \vv=\vw$. We write
  \begin{gather}
    \vv\parallel\vw.
  \end{gather}
  Mot that for normed vectors, we have $\alpha = \pm1$ if $V=\R^n$ and
  $\alpha = e^{i\phi}$ if $V=\C^n$.
\end{Definition}

\subsection{Matrix notation for bases}
\input{bases}
\subsection{Similarity transformations}
\input{similarity}
\section{Inner products and orthogonality}
\input{inner}
\section{Projections}
\input{projections}
\section{The determinant}
\input{determinant}

\chapter{Basics from Numerical Analysis}


\section{Matrix norms and spectral radius}

\begin{Definition*}{matrix-norm}{Matrix norm}
  The space of matrices $\Cnn$ is a vector space of dimension $n^2$ and thus any vector space norm is a norm on this space. For an actual matrix norm, we require compatibility with matrix multiplication, namely
  \begin{gather}
    \norm{\mata\matb} \le \norm{\mata}\norm{\matb},
  \end{gather}
  for any matrices where this makes sense. A matrix norm is called \define{operator norm} or \define{induced norm}, if $\mata\colon V\to W$ and
  \begin{gather}
    \norm\mata = \norm{\mata}_{V\to W} = \sup_{\vv\in V}\frac{\norm{\mata\vv}_W}{\norm{\vv}_V}.
  \end{gather}
\end{Definition*}

\begin{todo}
  Corollary on norm of identity, example: Frobenius norm is not an operator norm
\end{todo}

\begin{Definition}{spectral-radius}
  The \define{spectral radius} of a matrix $\mata\in\Cnn$ is the
  maximal absolute value of its eigenvalues, that is
  \begin{gather}
    \rho(\mata) = \max_{\lambda\in\sigma(\mata)} \abs{\lambda}.
  \end{gather}
\end{Definition}

\begin{Lemma*}{spectral-radius}{Properties of the spectral radius}
  For any matrix norm $\norm\cdot$ and for any matrix $\mata\in\Cnn$ there holds
  \begin{gather}
    \rho(\mata) = \lim_{k\to\infty} \norm{\mata^k}^{1/k}.
  \end{gather}

  The sequence $\vx^{(k)} = A^k\vx$ converges to zero for all
  $\vx\in\C^n$ if and only if $\rho(\mata)<1$.

  For any $\epsilon>0$
  there is a matrix norm $\norm\cdot$ such that
  \begin{gather}
    \norm{\mata} \le (1+\epsilon) \rho(\mata) \qquad \forall \mata\in\Cnn.
  \end{gather}
\end{Lemma*}

\begin{Definition}{matrix-condition}
  The \define{condition number} of a matrix $\mata\in\Cnn$ for a given
  matrix norm is
  \begin{gather*}
    \cond\mata = \norm{\mata}\norm{\mata^{-1}}.
  \end{gather*}
  In particular, we define the \define{spectral condition number}
 $\cond_2\mata = \norm{\mata}_2\norm{\mata^{-1}}_2$.
\end{Definition}

\begin{Example}{matrix-norms}
  The operator norm induced by the maximum norm is the \define{row sum norm}
  \begin{gather}
    \norm{\mata}_\infty = \max_i \sum_j \abs{a_{ij}}.
  \end{gather}
  The operator norm induced by the 1-norm is the \define{column sum norm}
  \begin{gather}
    \norm{\mata}_1 = \max_j \sum_i \abs{a_{ij}}.
  \end{gather}
  The operator norm induced by the \putindex{Euclidean norm} is the \define{spectral norm}
  \begin{gather}
    \norm{\mata}_2 = \sqrt{\lambda_{\max}(\mata^*\mata)}.
  \end{gather}
\end{Example}

\section{Chebyshev polynomials}
\input{chebyshev}

\section{Finite difference methods}
\input{fd}

\input{programming}

\nocite{Rannacher18nla}
\bibliographystyle{alpha}
\bibliography{all}
\printindex

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
